{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "task1,2_character_lm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R53XRkN5b3ap",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 2. Language modeling.\n",
        "\n",
        "This task is devoted to language modeling. Its goal is to write in PyTorch an RNN-based language model. Since word-based language modeling requires long training and is memory-consuming due to large vocabulary, we start with character-based language modeling. We are going to train the model to generate words as sequence of characters. During training we teach it to predict characters of the words in the training set.\n",
        "\n",
        "\n",
        "\n",
        "## Task 1. Character-based language modeling: data preparation (15 points)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIDh0w42b3aq",
        "colab_type": "text"
      },
      "source": [
        "We train the language models on the materials of **Sigmorphon 2018 Shared Task**. First, download the Russian datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QLj5gMub3ar",
        "colab_type": "code",
        "outputId": "ba696f83-7e90-4efa-93ac-00d53d8ef30e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/sigmorphon/conll2018/master/task1/surprise/russian-train-high\n",
        "!wget https://raw.githubusercontent.com/sigmorphon/conll2018/master/task1/surprise/russian-dev\n",
        "!wget https://raw.githubusercontent.com/sigmorphon/conll2018/master/task1/surprise/russian-test"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-08 18:03:16--  https://raw.githubusercontent.com/sigmorphon/conll2018/master/task1/surprise/russian-train-high\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 533309 (521K) [text/plain]\n",
            "Saving to: ‘russian-train-high’\n",
            "\n",
            "\rrussian-train-high    0%[                    ]       0  --.-KB/s               \rrussian-train-high  100%[===================>] 520.81K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2020-04-08 18:03:17 (14.0 MB/s) - ‘russian-train-high’ saved [533309/533309]\n",
            "\n",
            "--2020-04-08 18:03:20--  https://raw.githubusercontent.com/sigmorphon/conll2018/master/task1/surprise/russian-dev\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 53671 (52K) [text/plain]\n",
            "Saving to: ‘russian-dev’\n",
            "\n",
            "russian-dev         100%[===================>]  52.41K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2020-04-08 18:03:20 (3.44 MB/s) - ‘russian-dev’ saved [53671/53671]\n",
            "\n",
            "--2020-04-08 18:03:22--  https://raw.githubusercontent.com/sigmorphon/conll2018/master/task1/surprise/russian-test\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 53514 (52K) [text/plain]\n",
            "Saving to: ‘russian-test’\n",
            "\n",
            "russian-test        100%[===================>]  52.26K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2020-04-08 18:03:22 (3.68 MB/s) - ‘russian-test’ saved [53514/53514]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEOoLBiIb3av",
        "colab_type": "text"
      },
      "source": [
        "**1.1 (1 points)**\n",
        "All the files contain tab-separated triples ```<lemma>-<form>-<tags>```, where ```<form>``` may contain spaces (*будете соответствовать*). Write a function that loads a list of all word forms, that do not contain spaces.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nE3ACfRgb3aw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_infile(infile):\n",
        "    \"\"\"\n",
        "    == YOUR CODE HERE ==\n",
        "    \"\"\"\n",
        "    words = []\n",
        "    with open(infile) as file:\n",
        "      for line in file:\n",
        "        form = line.split('\\t')[1]\n",
        "        words.append('_'.join(form.split()))\n",
        "\n",
        "    return words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNVeZUN7b3az",
        "colab_type": "code",
        "outputId": "80aeefc3-ae7f-4808-8564-8050725c3f5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "train_words = read_infile(\"russian-train-high\")\n",
        "dev_words = read_infile(\"russian-dev\")\n",
        "test_words = read_infile(\"russian-test\")\n",
        "print(len(train_words), len(dev_words), len(test_words))\n",
        "print(*train_words[:10])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000 1000 1000\n",
            "валлонскому незаконченным истрёпывав личного серьгам необоснованным тюти заросла будете_облётывать идеальна\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUwzLh_Zb3a1",
        "colab_type": "text"
      },
      "source": [
        "**1.2 (2 points)** Write a **Vocabulary** class that allows to transform symbols into their indexes. The class should have the method ```__call__``` that applies this transformation to sequences of symbols and batches of sequences as well. You can also use [SimpleVocabulary](https://github.com/deepmipt/DeepPavlov/blob/c10b079b972493220c82a643d47d718d5358c7f4/deeppavlov/core/data/simple_vocab.py#L31) from DeepPavlov. Fit an instance of this class on the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxv1D2Tld0aS",
        "colab_type": "code",
        "outputId": "4065339c-e12d-4c83-88d9-a05786554415",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "! pip install deeppavlov"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting deeppavlov\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/ff/8e6ad196e1bc732f6967452b2a245345aa72c1b8007d6ddf95c7f60a04e4/deeppavlov-0.8.0-py3-none-any.whl (750kB)\n",
            "\r\u001b[K     |▍                               | 10kB 13.1MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 2.6MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 3.3MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 2.7MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51kB 3.1MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61kB 3.6MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 3.8MB/s eta 0:00:01\r\u001b[K     |███▌                            | 81kB 4.3MB/s eta 0:00:01\r\u001b[K     |████                            | 92kB 4.5MB/s eta 0:00:01\r\u001b[K     |████▍                           | 102kB 4.6MB/s eta 0:00:01\r\u001b[K     |████▉                           | 112kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 122kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 133kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 143kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 153kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████                         | 163kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 174kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 184kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 194kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 204kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 215kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 225kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████                      | 235kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 245kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 256kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 266kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 276kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 286kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 296kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 307kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 317kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 327kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 337kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 348kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 358kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 368kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 378kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 389kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 399kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 409kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 419kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 430kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 440kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 450kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 460kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 471kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 481kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 491kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 501kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 512kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 522kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 532kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 542kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 552kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 563kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 573kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 583kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 593kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 604kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 614kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 624kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 634kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 645kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 655kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 665kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 675kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 686kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 696kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 706kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 716kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 727kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 737kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 747kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 757kB 4.6MB/s \n",
            "\u001b[?25hCollecting overrides==2.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ac/98/2430afd204c48ac0a529d439d7e22df8fa603c668d03456b5947cb59ec36/overrides-2.7.0.tar.gz\n",
            "Collecting pymorphy2==0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
            "\r\u001b[K     |███████                         | 10kB 30.6MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 20kB 37.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 30kB 43.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 40kB 41.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 7.8MB/s \n",
            "\u001b[?25hCollecting pyopenssl==19.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/de/f8342b68fa9e981d348039954657bdf681b2ab93de27443be51865ffa310/pyOpenSSL-19.1.0-py2.py3-none-any.whl (53kB)\n",
            "\r\u001b[K     |██████                          | 10kB 28.0MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 20kB 34.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 30kB 40.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 40kB 40.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 51kB 26.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (1.4.1)\n",
            "Collecting Cython==0.29.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/df/d1/4d3f8a7a920e805488a966cc6ab55c978a712240f584445d703c08b9f405/Cython-0.29.14-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 20.5MB/s \n",
            "\u001b[?25hCollecting uvicorn==0.11.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/24/11f4b4bf3963ead6de570feeae49eeced02f6768cf1f68e16f4b16d3b0aa/uvicorn-0.11.1-py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.0MB/s \n",
            "\u001b[?25hCollecting nltk==3.4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 40.9MB/s \n",
            "\u001b[?25hCollecting fastapi==0.47.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/a7/4804d7abf8a1544d079d50650af872387154ebdac5bd07d54b2e60e2b334/fastapi-0.47.1-py3-none-any.whl (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.1MB/s \n",
            "\u001b[?25hCollecting pytelegrambotapi==3.6.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/ab/99c606f69fcda57e35788b913dd34c9d9acb48dd26349141b3855dcf6351/pyTelegramBotAPI-3.6.7.tar.gz (65kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 9.4MB/s \n",
            "\u001b[?25hCollecting fuzzywuzzy==0.17.0\n",
            "  Downloading https://files.pythonhosted.org/packages/d8/f1/5a267addb30ab7eaa1beab2b9323073815da4551076554ecc890a3595ec9/fuzzywuzzy-0.17.0-py2.py3-none-any.whl\n",
            "Collecting aio-pika==6.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/07/196a4115cbef31fa0c3dabdea146f02dffe5e49998341d20dbe2278953bc/aio_pika-6.4.1-py3-none-any.whl (40kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.3MB/s \n",
            "\u001b[?25hCollecting pymorphy2-dicts-ru\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/9b/358faaff410f65a4ad159275e897b5956dcb20576c5b8e764b971c1634d7/pymorphy2_dicts_ru-2.4.404381.4453942-py2.py3-none-any.whl (8.0MB)\n",
            "\u001b[K     |████████████████████████████████| 8.0MB 15.0MB/s \n",
            "\u001b[?25hCollecting pandas==0.25.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/3f/f6a428599e0d4497e1595030965b5ba455fd8ade6e977e3c819973c4b41d/pandas-0.25.3-cp36-cp36m-manylinux1_x86_64.whl (10.4MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4MB 54.1MB/s \n",
            "\u001b[?25hCollecting pydantic==1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/24/e78cf017628e7eaed20cb040999b1ecc69f872da53dfd0d9aed40c0fa5f1/pydantic-1.3-cp36-cp36m-manylinux2010_x86_64.whl (7.3MB)\n",
            "\u001b[K     |████████████████████████████████| 7.3MB 21.2MB/s \n",
            "\u001b[?25hCollecting requests==2.22.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.1MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.21.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/04/49633f490f726da6e454fddc8e938bbb5bfed2001681118d3814c219b723/scikit_learn-0.21.2-cp36-cp36m-manylinux1_x86_64.whl (6.7MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7MB 39.0MB/s \n",
            "\u001b[?25hCollecting tqdm==4.41.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/c9/7fc20feac72e79032a7c8138fd0d395dc6d8812b5b9edf53c3afd0b31017/tqdm-4.41.1-py2.py3-none-any.whl (56kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (2.10.0)\n",
            "Collecting numpy==1.18.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/e6/45f71bd24f4e37629e9db5fb75caab919507deae6a5a257f9e4685a5f931/numpy-1.18.0-cp36-cp36m-manylinux1_x86_64.whl (20.1MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1MB 152kB/s \n",
            "\u001b[?25hCollecting rusenttokenize==0.0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/25/4c/a2f00be5def774a3df2e5387145f1cb54e324607ec4a7e23f573645946e7/rusenttokenize-0.0.5-py3-none-any.whl\n",
            "Collecting pymorphy2-dicts<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 18.8MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2==0.8->deeppavlov) (0.6.2)\n",
            "Collecting cryptography>=2.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/2d/29d2638b8df016526182594166c220913dafba3da0019b0776ff1bbc8ede/cryptography-2.9-cp35-abi3-manylinux2010_x86_64.whl (2.7MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7MB 53.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.6/dist-packages (from pyopenssl==19.1.0->deeppavlov) (1.12.0)\n",
            "Collecting httptools==0.0.13; sys_platform != \"win32\" and sys_platform != \"cygwin\" and platform_python_implementation != \"pypy\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/03/215969db11abe8741e9c266a4cbe803a372bd86dd35fa0084c4df6d4bd00/httptools-0.0.13.tar.gz (104kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 55.2MB/s \n",
            "\u001b[?25hCollecting uvloop>=0.14.0; sys_platform != \"win32\" and sys_platform != \"cygwin\" and platform_python_implementation != \"pypy\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/48/586225bbb02d3bdca475b17e4be5ce5b3f09da2d6979f359916c1592a687/uvloop-0.14.0-cp36-cp36m-manylinux2010_x86_64.whl (3.9MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9MB 51.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: click==7.* in /usr/local/lib/python3.6/dist-packages (from uvicorn==0.11.1->deeppavlov) (7.1.1)\n",
            "Collecting websockets==8.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/d9/856af84843912e2853b1b6e898ac8b802989fcf9ecf8e8445a1da263bf3b/websockets-8.1-cp36-cp36m-manylinux2010_x86_64.whl (78kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.9MB/s \n",
            "\u001b[?25hCollecting h11<0.10,>=0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/fd/3dad730b0f95e78aeeb742f96fa7bbecbdd56a58e405d3da440d5bfb90c6/h11-0.9.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.4MB/s \n",
            "\u001b[?25hCollecting starlette<=0.12.9,>=0.12.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/95/2220fe5bf287e693a6430d8ee36c681b0157035b7249ec08f8fb36319d16/starlette-0.12.9.tar.gz (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.3MB/s \n",
            "\u001b[?25hCollecting yarl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/8f/0209fc5d975f839344c33c822ff2f7ef80f6b1e984673a5a68f960bfa583/yarl-1.4.2-cp36-cp36m-manylinux1_x86_64.whl (252kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 53.7MB/s \n",
            "\u001b[?25hCollecting aiormq<4,>=3.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/f8/77a1694064c677afaaae111e28e2b32dd70c5f9dce3836bad0df20f27201/aiormq-3.2.1-py3-none-any.whl\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas==0.25.3->deeppavlov) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas==0.25.3->deeppavlov) (2.8.1)\n",
            "Requirement already satisfied: dataclasses>=0.6; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from pydantic==1.3->deeppavlov) (0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov) (2019.11.28)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov) (3.0.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.21.2->deeppavlov) (0.14.1)\n",
            "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.8->pyopenssl==19.1.0->deeppavlov) (1.14.0)\n",
            "Collecting multidict>=4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/2e/3ab2f1fb72571f75013db323a3799d505d99f3bc203513604f1ffb9b7858/multidict-4.7.5-cp36-cp36m-manylinux1_x86_64.whl (148kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 60.5MB/s \n",
            "\u001b[?25hCollecting pamqp==2.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/56/afa06143361e640c9159d828dadc95fc9195c52c95b4a97d136617b0166d/pamqp-2.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.8->pyopenssl==19.1.0->deeppavlov) (2.20)\n",
            "Building wheels for collected packages: overrides, nltk, pytelegrambotapi, httptools, starlette\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-2.7.0-cp36-none-any.whl size=5600 sha256=98050138501575e988541e07005b8c2737ea3dfe27a70951aec0c8e5ca7d308d\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/7c/ef/80508418b67d87371c5b3de49e03eb22ee7c1d19affb5099f8\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-cp36-none-any.whl size=1449904 sha256=d9dcf9b88a831614d74d130b88a4f8282bcfad1c0b6579475b49a9d2703bef6d\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n",
            "  Building wheel for pytelegrambotapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytelegrambotapi: filename=pyTelegramBotAPI-3.6.7-cp36-none-any.whl size=47178 sha256=f1b0c4753b44d92b8859cbee702b30da2c9af896e3361beac76a70052c1ec8b1\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/40/18/8a34153f95ef0dc19e3954898e5a5079244b76a8afdd7d0ec5\n",
            "  Building wheel for httptools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for httptools: filename=httptools-0.0.13-cp36-cp36m-linux_x86_64.whl size=212535 sha256=bfa5e44b5929d37bee001c66df34e60fbdf4a021846337d6ec3491070bf4702d\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/3e/2e/013f99b42efc25cf3589730cf380738e46b1e5edaf2f78d525\n",
            "  Building wheel for starlette (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for starlette: filename=starlette-0.12.9-cp36-none-any.whl size=57245 sha256=3f5a4ba2e31c567699f73c279a8c6d2f1ec3ac41bf3238f0ff9736648bbc9573\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/51/5b/3828d52e185cafad941c4291b6f70894d0794be28c70addae5\n",
            "Successfully built overrides nltk pytelegrambotapi httptools starlette\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.0.0; python_version >= \"3.0\", but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.21.0, but you'll have requests 2.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: overrides, pymorphy2-dicts, dawg-python, pymorphy2, cryptography, pyopenssl, Cython, httptools, uvloop, websockets, h11, uvicorn, nltk, pydantic, starlette, fastapi, requests, pytelegrambotapi, fuzzywuzzy, multidict, yarl, pamqp, aiormq, aio-pika, pymorphy2-dicts-ru, numpy, pandas, scikit-learn, tqdm, rusenttokenize, deeppavlov\n",
            "  Found existing installation: Cython 0.29.16\n",
            "    Uninstalling Cython-0.29.16:\n",
            "      Successfully uninstalled Cython-0.29.16\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "  Found existing installation: requests 2.21.0\n",
            "    Uninstalling requests-2.21.0:\n",
            "      Successfully uninstalled requests-2.21.0\n",
            "  Found existing installation: numpy 1.18.2\n",
            "    Uninstalling numpy-1.18.2:\n",
            "      Successfully uninstalled numpy-1.18.2\n",
            "  Found existing installation: pandas 1.0.3\n",
            "    Uninstalling pandas-1.0.3:\n",
            "      Successfully uninstalled pandas-1.0.3\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Found existing installation: tqdm 4.38.0\n",
            "    Uninstalling tqdm-4.38.0:\n",
            "      Successfully uninstalled tqdm-4.38.0\n",
            "Successfully installed Cython-0.29.14 aio-pika-6.4.1 aiormq-3.2.1 cryptography-2.9 dawg-python-0.7.2 deeppavlov-0.8.0 fastapi-0.47.1 fuzzywuzzy-0.17.0 h11-0.9.0 httptools-0.0.13 multidict-4.7.5 nltk-3.4.5 numpy-1.18.0 overrides-2.7.0 pamqp-2.3.0 pandas-0.25.3 pydantic-1.3 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985 pymorphy2-dicts-ru-2.4.404381.4453942 pyopenssl-19.1.0 pytelegrambotapi-3.6.7 requests-2.22.0 rusenttokenize-0.0.5 scikit-learn-0.21.2 starlette-0.12.9 tqdm-4.41.1 uvicorn-0.11.1 uvloop-0.14.0 websockets-8.1 yarl-1.4.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "pandas",
                  "requests",
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06tKiUqkb3a2",
        "colab_type": "code",
        "outputId": "e054e47e-b29b-43a9-bba1-0f9ce4174994",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "from deeppavlov.core.data.simple_vocab import SimpleVocabulary\n",
        "\"\"\"\n",
        "== YOUR CODE HERE ==\n",
        "\"\"\"\n",
        "\n",
        "vocab = SimpleVocabulary(save_path='/content')\n",
        "vocab.fit([list(x) for x in train_words])#  + ['BEGIN', 'END'])\n",
        "print(len(vocab))\n",
        "\n",
        "BEGIN_INDEX = len(vocab)\n",
        "END_INDEX = len(vocab) + 1"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-04-08 18:04:12.996 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 49: No load path is set for SimpleVocabulary in 'infer' mode. Using save path instead\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "52\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKLVBVOBb3a6",
        "colab_type": "text"
      },
      "source": [
        "**1.3 (2 points)** Write a **Dataset** class, which should be inherited from ```torch.utils.data.Dataset```. It should take a list of words and the ```vocab``` as initialization arguments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yb8CnctAm-HG",
        "colab_type": "code",
        "outputId": "27ed90b7-1881-413b-cd5d-2a712eda02f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "t = torch.Tensor([1, 2, 3])\n",
        "print(t)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 2., 3.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K3Wu8TOWlPTt",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset as TorchDataset\n",
        "\n",
        "class Dataset(TorchDataset):\n",
        "    \n",
        "    \"\"\"Custom data.Dataset compatible with data.DataLoader.\"\"\"\n",
        "    def __init__(self, data, vocab):\n",
        "        self.data = data\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Returns one tensor pair (source and target). The source tensor corresponds to the input word,\n",
        "        with \"BEGIN\" and \"END\" symbols attached. The target tensor should contain the answers\n",
        "        for the language model that obtain these word as input.        \n",
        "        \"\"\"\n",
        "        \n",
        "        indexed_word = [vocab[char] for char in self.data[index]]\n",
        "        return torch.Tensor([BEGIN_INDEX] + indexed_word), torch.Tensor(indexed_word + [END_INDEX])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSPkZEm1b3a9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = Dataset(train_words, vocab)\n",
        "dev_dataset = Dataset(dev_words, vocab)\n",
        "test_dataset = Dataset(test_words, vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR5cPdXRb3bA",
        "colab_type": "text"
      },
      "source": [
        "**1.4 (3 points)** Use a standard ```torch.utils.data.DataLoader``` to obtain an iterable over batches. Print the shape of first 10 input batches with ```batch_size=1```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qVouJr9b3bB",
        "colab_type": "code",
        "outputId": "4cc5455e-d520-422a-ae85-09be031ad55e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "dl = DataLoader(train_dataset)\n",
        "i = 0\n",
        "for tests, test_labels in dl:  \n",
        "  print(tests.shape)\n",
        "  \n",
        "  i += 1\n",
        "  if i == 10:\n",
        "    break"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 12])\n",
            "torch.Size([1, 14])\n",
            "torch.Size([1, 11])\n",
            "torch.Size([1, 8])\n",
            "torch.Size([1, 8])\n",
            "torch.Size([1, 15])\n",
            "torch.Size([1, 5])\n",
            "torch.Size([1, 8])\n",
            "torch.Size([1, 18])\n",
            "torch.Size([1, 9])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgPsGMrtb3bF",
        "colab_type": "text"
      },
      "source": [
        "**(1.5) 1 point** Explain, why this does not work with larger batch size."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hie86CO43KoE",
        "colab_type": "text"
      },
      "source": [
        "It is well known that too large of a batch size will lead to poor generalization (although currently it’s not known why this is so)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVfUVGRvb3bG",
        "colab_type": "text"
      },
      "source": [
        "**(1.6) 5 points** Write a function **collate** that allows you to deal with batches of greater size. See [discussion](https://discuss.pytorch.org/t/dataloader-for-various-length-of-data/6418/8) for an example. Implement your function as a class ```__call__``` method to make it more flexible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTdXUCHKb3bG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_tensor(vec, length, dim, pad_symbol):\n",
        "    \"\"\"\n",
        "    Pads a vector ``vec`` up to length ``length`` along axis ``dim`` with pad symbol ``pad_symbol``.\n",
        "    \"\"\"\n",
        "\n",
        "    pad_size_list = list(vec.shape)\n",
        "    pad_size_list[dim] = length - vec.size(dim)\n",
        "    padding = torch.Tensor().new_full(tuple(pad_size_list), pad_symbol)\n",
        "    return torch.cat([vec, padding], dim=dim)\n",
        "\n",
        "class Padder:\n",
        "    def __init__(self, dim=0, pad_symbol=0):\n",
        "        self.dim = dim\n",
        "        self.pad_symbol = pad_symbol\n",
        "        \n",
        "\n",
        "    def pad_collate(self, batch):\n",
        "        \"\"\"\n",
        "        args:\n",
        "            batch - list of (tensor, label)\n",
        "\n",
        "        return:\n",
        "            xs - a tensor of all examples in 'batch' after padding\n",
        "            ys - a LongTensor of all labels in batch\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        # find longest sequence\n",
        "        max_len = max(map(lambda x: x[0].shape[self.dim], batch))\n",
        "        def decorated_pad_tensor(tensor):\n",
        "          return pad_tensor(tensor, length=max_len, dim=self.dim, pad_symbol=self.pad_symbol)\n",
        "        # pad according to max_len\n",
        "        # batch = map(lambda sample_and_label: (pad_tensor(sample_and_label[0], length=max_len, dim=self.dim, pad_symbol=self.pad_symbol), sample_and_label[1]), batch)\n",
        "\n",
        "        # stack all\n",
        "        xs = torch.stack(tuple(map(lambda x: decorated_pad_tensor(x[0]), batch)), dim=self.dim).type(torch.LongTensor)\n",
        "        ys = torch.stack(tuple(map(lambda x: decorated_pad_tensor(x[1]), batch)), dim=self.dim).type(torch.LongTensor)\n",
        "        mask = torch.stack([pad_tensor(torch.ones(y.shape), max_len, self.dim, 0) for y in ys]).type(torch.LongTensor)\n",
        "\n",
        "        return xs, ys, mask\n",
        "        \n",
        "    def __call__(self, batch):\n",
        "        return self.pad_collate(batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhZ1kUBOb3bJ",
        "colab_type": "text"
      },
      "source": [
        "**(1.7) 1 points** Again, use ```torch.utils.data.DataLoader``` to obtain an iterable over batches. Print the shape of first 10 input batches with the batch size you like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIoVFRIjb3bJ",
        "colab_type": "code",
        "outputId": "c436a236-0c7d-48e5-b99b-74e7092efbcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "dataset = DataLoader(train_dataset, collate_fn=Padder(pad_symbol=END_INDEX), batch_size=20, shuffle=True)\n",
        "i = 0\n",
        "for tests, test_labels, mask in dataset:  \n",
        "  print(tests.shape, test_labels.shape)\n",
        "  \n",
        "  i += 1\n",
        "  if i == 10:\n",
        "    break"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([20, 21]) torch.Size([20, 21])\n",
            "torch.Size([20, 19]) torch.Size([20, 19])\n",
            "torch.Size([20, 25]) torch.Size([20, 25])\n",
            "torch.Size([20, 16]) torch.Size([20, 16])\n",
            "torch.Size([20, 15]) torch.Size([20, 15])\n",
            "torch.Size([20, 16]) torch.Size([20, 16])\n",
            "torch.Size([20, 18]) torch.Size([20, 18])\n",
            "torch.Size([20, 15]) torch.Size([20, 15])\n",
            "torch.Size([20, 18]) torch.Size([20, 18])\n",
            "torch.Size([20, 20]) torch.Size([20, 20])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHKE1Esvb3bM",
        "colab_type": "text"
      },
      "source": [
        "## Task 2. Character-based language modeling. (35 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQfrpAMHb3bP",
        "colab_type": "text"
      },
      "source": [
        "**2.1 (5 points)** Write a network that performs language modeling. It should include three layers:\n",
        "1. **Embedding** layer that transforms input symbols into vectors.\n",
        "2. An **RNN** layer that outputs a sequence of hidden states (you may use https://pytorch.org/docs/stable/nn.html#gru).\n",
        "3. A **Linear** layer with ``softmax`` activation that produces the output distribution for each symbol."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyq9Mw8Ab3bP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "class RNNLM(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embeddings_dim, hidden_size):\n",
        "        super(RNNLM, self).__init__()\n",
        "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embeddings_dim)\n",
        "        self.rnn = nn.GRU(input_size=embedding_dim, hidden_size=hidden_size, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "      \n",
        "    def forward(self, inputs, hidden=None):\n",
        "        embedded = self.embedding(inputs)\n",
        "        rnn_out, hidden = self.rnn(embedded)#, torch.zeros(1, inputs[0].shape[0], self.hidden_size))\n",
        "        output = self.linear(rnn_out)\n",
        "        \n",
        "        return output\n",
        "        # print(torch.tensor([max(char_weights) for char_weights in output]))\n",
        "        #return torch.tensor([torch.argmax(char_weights) for char_weights in output[0]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcEiP3Ujb3bT",
        "colab_type": "text"
      },
      "source": [
        "**2.2 (1 points)** Write a function ``validate_on_batch`` that takes as input a model, a batch of inputs and a batch of outputs, and the loss criterion, and outputs the loss tensor for the whole batch. This loss should not be normalized."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiVXU6MUb3bT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validate_on_batch(model, criterion, x, y):\n",
        "    y = y.view(-1)\n",
        "    scores = model(x)\n",
        "    scores = scores.view(-1, scores.shape[-1])\n",
        "    loss = criterion(scores, y)\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHpjOSBrb3bV",
        "colab_type": "text"
      },
      "source": [
        "**2.3 (1 points)** Write a function ``train_on_batch`` that accepts all the arguments of ``validate_on_batch`` and also an optimizer, calculates loss and makes a single step of gradient optimization. This function should call ``validate_on_batch`` inside."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx28g7cjb3bW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_on_batch(model, criterion, x, y, mask, optimizer):\n",
        "    loss = validate_on_batch(model, criterion, x, y)\n",
        "    nopad_chars = mask.sum()\n",
        "    loss = (loss * mask.view(-1)).sum() / nopad_chars\n",
        "\n",
        "    # Zero grads\n",
        "    optimizer.zero_grad()\n",
        "    # Backpropagate\n",
        "    loss.backward()\n",
        "    # Update weights\n",
        "    optimizer.step()\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJmZLnFsb3bZ",
        "colab_type": "text"
      },
      "source": [
        "**2.4 (3 points)** Write a training loop. You should define your ``RNNLM`` model, the criterion, the optimizer and the hyperparameters (number of epochs and batch size). Then train the model for a required number of epochs. On each epoch evaluate the average training loss and the average loss on the validation set. \n",
        "\n",
        "**2.5 (3 points)** Do not forget to average your loss over only non-padding symbols, otherwise it will be too optimistic."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngUdwIg_b3ba",
        "colab_type": "code",
        "outputId": "c4f5ffcd-fff8-4d9d-d361-8ae3e50612f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "epoch_num = 3\n",
        "embedding_dim = 300\n",
        "hidden_dim = 300\n",
        "vocab_size = len(vocab) +2\n",
        "lr = 1e-3\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "model = RNNLM(vocab_size, embedding_dim, hidden_dim)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
        "\n",
        "losses = []\n",
        "\n",
        "for epoch in range(epoch_num):\n",
        "  for x, y, mask in dataset:\n",
        "    loss = train_on_batch(model, criterion, x, y, mask, optimizer)\n",
        "    # print('Loss: {:6.4f}'.format(loss.item()))\n",
        "    losses.append(loss.item())\n",
        "\n",
        "\n",
        "plt.plot(losses)\n",
        "  # with torch.no_grad():\n",
        "  #   matches, total = 0, 0\n",
        "  #   for x, y, mask in dataset:\n",
        "  #     _, batch_out = predictions.max(dim=1)\n",
        "\n",
        "  #     # Remove batch\n",
        "  #     batch_out = batch_out.squeeze(1)\n",
        "\n",
        "  #     # Calculate accuracy\n",
        "  #     matches += torch.eq(batch_out, y).sum().item()\n",
        "  #     total += torch.numel(batch_out)\n",
        "  \n",
        "  # accuracy = matches / total\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # plt.title('Accuracy: {:4.2f}%'.format(accuracy * 100))\n",
        "\n",
        "  # plt.plot(range(1, len(vocab)), (np.arange(1, len(vocab)) - 10) %  len(vocab))\n",
        "  # with torch.no_grad():\n",
        "  #     plt.plot(range(1, len(vocab)), F.softmax(model(torch.tensor(range(1, len(vocab)))), 1).max(dim=1)[1])\n",
        "  # plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fd8c84f2e10>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkCH8P/TjuHuLrBAkAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzuroqBCb3bc",
        "colab_type": "text"
      },
      "source": [
        "**2.6 (5 points)** Write a function **predict_on_batch** that outputs letter probabilities of all words in the batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "turLJRjib3bd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_on_batch(x, model):\n",
        "    out = model(x)\n",
        "    return torch.softmax(out, dim=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzdV0nU8b3bg",
        "colab_type": "text"
      },
      "source": [
        "**2.7 (1 points)** Calculate the letter probabilities for all words in the test dataset. Print them for 20 last words. Do not forget to disable shuffling in the ``DataLoader``."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GysbAJpNb3bh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9825c848-991a-47d3-c373-f3ba5290d13f"
      },
      "source": [
        "data_loader = DataLoader(train_dataset, collate_fn=Padder(pad_symbol=END_INDEX), batch_size=20)\n",
        "\n",
        "for x, y, mask in data_loader:\n",
        "  out = predict_on_batch(x, model)\n",
        "\n",
        "for i in range(1, 21):\n",
        "  print(out[-i])\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[8.2360e-02, 3.5978e-02, 3.7318e-03,  ..., 5.0180e-05, 5.8638e-05,\n",
            "         6.9420e-04],\n",
            "        [2.2199e-01, 3.5644e-02, 5.1312e-02,  ..., 4.9920e-05, 4.8833e-05,\n",
            "         1.8221e-04],\n",
            "        [1.2899e-02, 7.2415e-03, 6.1174e-02,  ..., 1.0374e-04, 7.5210e-05,\n",
            "         7.4501e-04],\n",
            "        ...,\n",
            "        [1.6743e-07, 1.4894e-07, 7.4860e-07,  ..., 2.9917e-08, 4.4029e-08,\n",
            "         9.9997e-01],\n",
            "        [1.6685e-07, 1.4890e-07, 7.3603e-07,  ..., 2.9862e-08, 4.4072e-08,\n",
            "         9.9997e-01],\n",
            "        [1.6639e-07, 1.4878e-07, 7.2549e-07,  ..., 2.9796e-08, 4.4073e-08,\n",
            "         9.9997e-01]], grad_fn=<SelectBackward>)\n",
            "tensor([[8.2360e-02, 3.5978e-02, 3.7318e-03,  ..., 5.0180e-05, 5.8638e-05,\n",
            "         6.9420e-04],\n",
            "        [3.3387e-01, 1.3861e-01, 8.6948e-02,  ..., 2.4439e-05, 1.3735e-05,\n",
            "         1.5135e-05],\n",
            "        [6.6381e-03, 2.1928e-03, 7.5025e-03,  ..., 7.3370e-05, 6.8939e-05,\n",
            "         1.0687e-03],\n",
            "        ...,\n",
            "        [1.6378e-07, 1.6295e-07, 7.3299e-07,  ..., 2.7847e-08, 4.0810e-08,\n",
            "         9.9997e-01],\n",
            "        [1.6109e-07, 1.5918e-07, 7.1306e-07,  ..., 2.7893e-08, 4.1013e-08,\n",
            "         9.9997e-01],\n",
            "        [1.5974e-07, 1.5675e-07, 7.0022e-07,  ..., 2.7922e-08, 4.1158e-08,\n",
            "         9.9997e-01]], grad_fn=<SelectBackward>)\n",
            "tensor([[8.2360e-02, 3.5978e-02, 3.7318e-03,  ..., 5.0180e-05, 5.8638e-05,\n",
            "         6.9420e-04],\n",
            "        [3.5159e-02, 7.4793e-01, 3.8875e-02,  ..., 4.8379e-05, 3.5848e-05,\n",
            "         6.4926e-06],\n",
            "        [1.0327e-02, 2.5595e-03, 5.6687e-03,  ..., 6.8267e-05, 7.3820e-05,\n",
            "         2.3395e-04],\n",
            "        ...,\n",
            "        [1.5895e-07, 1.5262e-07, 7.8472e-07,  ..., 2.9649e-08, 4.3569e-08,\n",
            "         9.9997e-01],\n",
            "        [1.5838e-07, 1.5282e-07, 7.6466e-07,  ..., 2.9508e-08, 4.3521e-08,\n",
            "         9.9997e-01],\n",
            "        [1.5795e-07, 1.5297e-07, 7.4903e-07,  ..., 2.9446e-08, 4.3554e-08,\n",
            "         9.9997e-01]], grad_fn=<SelectBackward>)\n",
            "tensor([[8.2360e-02, 3.5978e-02, 3.7318e-03,  ..., 5.0180e-05, 5.8638e-05,\n",
            "         6.9420e-04],\n",
            "        [1.1470e-01, 5.6881e-02, 1.4406e-01,  ..., 3.9234e-05, 2.4770e-05,\n",
            "         3.3747e-05],\n",
            "        [5.7883e-05, 1.1748e-04, 7.3591e-04,  ..., 3.4094e-05, 2.2364e-05,\n",
            "         3.7483e-05],\n",
            "        ...,\n",
            "        [6.1877e-05, 1.1765e-04, 1.6772e-04,  ..., 1.9976e-05, 3.0223e-05,\n",
            "         1.3532e-03],\n",
            "        [1.1832e-05, 2.6164e-05, 8.7380e-05,  ..., 5.0951e-05, 6.1916e-05,\n",
            "         9.9072e-01],\n",
            "        [3.6503e-07, 4.9661e-07, 1.8721e-06,  ..., 2.5312e-07, 3.7361e-07,\n",
            "         9.9982e-01]], grad_fn=<SelectBackward>)\n",
            "tensor([[8.2360e-02, 3.5978e-02, 3.7318e-03,  ..., 5.0180e-05, 5.8638e-05,\n",
            "         6.9420e-04],\n",
            "        [3.2280e-03, 6.3122e-04, 2.7135e-03,  ..., 5.9430e-05, 4.7227e-05,\n",
            "         8.5529e-05],\n",
            "        [1.2983e-01, 8.7141e-02, 1.3141e-01,  ..., 7.9693e-05, 7.1489e-05,\n",
            "         5.3237e-04],\n",
            "        ...,\n",
            "        [1.7065e-07, 1.3344e-07, 6.6868e-07,  ..., 2.9242e-08, 4.1807e-08,\n",
            "         9.9997e-01],\n",
            "        [1.7033e-07, 1.3368e-07, 6.6729e-07,  ..., 2.9234e-08, 4.1925e-08,\n",
            "         9.9997e-01],\n",
            "        [1.7029e-07, 1.3411e-07, 6.6669e-07,  ..., 2.9206e-08, 4.2009e-08,\n",
            "         9.9997e-01]], grad_fn=<SelectBackward>)\n",
            "tensor([[8.2360e-02, 3.5978e-02, 3.7318e-03,  ..., 5.0180e-05, 5.8638e-05,\n",
            "         6.9420e-04],\n",
            "        [3.5306e-01, 5.1185e-02, 2.1666e-01,  ..., 3.0866e-05, 1.5294e-05,\n",
            "         5.1422e-05],\n",
            "        [4.4548e-01, 4.8859e-02, 1.4671e-01,  ..., 3.0649e-05, 2.1365e-05,\n",
            "         4.5196e-05],\n",
            "        ...,\n",
            "        [1.8568e-07, 1.6022e-07, 7.4211e-07,  ..., 3.1235e-08, 4.5939e-08,\n",
            "         9.9997e-01],\n",
            "        [1.7972e-07, 1.5480e-07, 7.2444e-07,  ..., 3.0860e-08, 4.5538e-08,\n",
            "         9.9997e-01],\n",
            "        [1.7608e-07, 1.5153e-07, 7.1314e-07,  ..., 3.0551e-08, 4.5193e-08,\n",
            "         9.9997e-01]], grad_fn=<SelectBackward>)\n",
            "tensor([[8.2360e-02, 3.5978e-02, 3.7318e-03,  ..., 5.0180e-05, 5.8638e-05,\n",
            "         6.9420e-04],\n",
            "        [1.4577e-03, 3.7237e-04, 6.6274e-04,  ..., 2.2541e-05, 2.4031e-05,\n",
            "         2.7844e-05],\n",
            "        [8.2629e-02, 1.6929e-02, 6.2168e-02,  ..., 9.6259e-05, 1.1062e-04,\n",
            "         5.3963e-04],\n",
            "        ...,\n",
            "        [1.3737e-07, 1.4559e-07, 5.8120e-07,  ..., 3.0705e-08, 4.4718e-08,\n",
            "         9.9997e-01],\n",
            "        [1.3903e-07, 1.4574e-07, 5.8137e-07,  ..., 3.0816e-08, 4.5029e-08,\n",
            "         9.9997e-01],\n",
            "        [1.4064e-07, 1.4592e-07, 5.8219e-07,  ..., 3.0858e-08, 4.5213e-08,\n",
            "         9.9997e-01]], grad_fn=<SelectBackward>)\n",
            "tensor([[8.2360e-02, 3.5978e-02, 3.7318e-03,  ..., 5.0180e-05, 5.8638e-05,\n",
            "         6.9420e-04],\n",
            "        [4.5997e-01, 4.2392e-02, 6.3028e-02,  ..., 7.3921e-06, 6.2995e-06,\n",
            "         2.2952e-05],\n",
            "        [4.3661e-03, 6.6481e-04, 3.5132e-03,  ..., 3.4606e-05, 3.5337e-05,\n",
            "         9.6309e-05],\n",
            "        ...,\n",
            "        [1.6917e-07, 1.4043e-07, 6.8396e-07,  ..., 2.8374e-08, 4.1330e-08,\n",
            "         9.9997e-01],\n",
            "        [1.6842e-07, 1.3998e-07, 6.7986e-07,  ..., 2.8627e-08, 4.1822e-08,\n",
            "         9.9997e-01],\n",
            "        [1.6805e-07, 1.3989e-07, 6.7715e-07,  ..., 2.8770e-08, 4.2133e-08,\n",
            "         9.9997e-01]], grad_fn=<SelectBackward>)\n",
            "tensor([[8.2360e-02, 3.5978e-02, 3.7318e-03,  ..., 5.0180e-05, 5.8638e-05,\n",
            "         6.9420e-04],\n",
            "        [9.5178e-02, 2.8281e-01, 5.5349e-01,  ..., 1.1367e-05, 7.8132e-06,\n",
            "         4.3335e-06],\n",
            "        [1.2968e-01, 1.2206e-02, 7.7497e-03,  ..., 5.3406e-05, 3.6720e-05,\n",
            "         5.0865e-04],\n",
            "        ...,\n",
            "        [1.6198e-07, 1.3879e-07, 6.8747e-07,  ..., 2.9047e-08, 4.2105e-08,\n",
            "         9.9997e-01],\n",
            "        [1.6297e-07, 1.3882e-07, 6.8640e-07,  ..., 2.9038e-08, 4.2229e-08,\n",
            "         9.9997e-01],\n",
            "        [1.6384e-07, 1.3901e-07, 6.8571e-07,  ..., 2.9000e-08, 4.2288e-08,\n",
            "         9.9997e-01]], grad_fn=<SelectBackward>)\n",
            "tensor([[8.2360e-02, 3.5978e-02, 3.7318e-03,  ..., 5.0180e-05, 5.8638e-05,\n",
            "         6.9420e-04],\n",
            "        [2.2199e-01, 3.5644e-02, 5.1312e-02,  ..., 4.9920e-05, 4.8833e-05,\n",
            "         1.8221e-04],\n",
            "        [4.4200e-03, 1.1866e-03, 1.2560e-02,  ..., 5.0535e-05, 3.9793e-05,\n",
            "         1.7636e-04],\n",
            "        ...,\n",
            "        [1.4914e-07, 1.4942e-07, 6.4934e-07,  ..., 2.9615e-08, 4.3812e-08,\n",
            "         9.9997e-01],\n",
            "        [1.4966e-07, 1.4892e-07, 6.4578e-07,  ..., 2.9452e-08, 4.3654e-08,\n",
            "         9.9997e-01],\n",
            "        [1.5036e-07, 1.4862e-07, 6.4335e-07,  ..., 2.9318e-08, 4.3524e-08,\n",
            "         9.9997e-01]], grad_fn=<SelectBackward>)\n",
            "tensor([[8.2360e-02, 3.5978e-02, 3.7318e-03,  ..., 5.0180e-05, 5.8638e-05,\n",
            "         6.9420e-04],\n",
            "        [3.9928e-01, 1.6023e-01, 1.3239e-02,  ..., 2.6358e-05, 2.0845e-05,\n",
            "         3.9992e-05],\n",
            "        [3.7318e-03, 3.2098e-03, 1.0344e-02,  ..., 6.2333e-05, 5.2060e-05,\n",
            "         4.8271e-04],\n",
            "        ...,\n",
            "        [1.4418e-07, 1.4601e-07, 7.0652e-07,  ..., 2.8557e-08, 3.9876e-08,\n",
            "         9.9997e-01],\n",
            "        [1.4501e-07, 1.4473e-07, 6.9294e-07,  ..., 2.8423e-08, 4.0082e-08,\n",
            "         9.9997e-01],\n",
            "        [1.4630e-07, 1.4425e-07, 6.8465e-07,  ..., 2.8300e-08, 4.0237e-08,\n",
            "         9.9997e-01]], grad_fn=<SelectBackward>)\n",
            "tensor([[8.2360e-02, 3.5978e-02, 3.7318e-03,  ..., 5.0180e-05, 5.8638e-05,\n",
            "         6.9420e-04],\n",
            "        [2.3550e-01, 2.4390e-01, 1.4709e-01,  ..., 2.9023e-05, 3.1910e-05,\n",
            "         1.5084e-04],\n",
            "        [5.2672e-03, 2.6024e-03, 8.8592e-03,  ..., 4.0348e-05, 4.2991e-05,\n",
            "         2.7543e-04],\n",
            "        ...,\n",
            "        [2.1128e-04, 7.8973e-04, 3.4423e-02,  ..., 2.7689e-05, 2.6084e-05,\n",
            "         5.1035e-02],\n",
            "        [8.0110e-05, 5.6517e-05, 1.3396e-04,  ..., 4.6561e-05, 7.2557e-05,\n",
            "         9.3823e-01],\n",
            "        [3.0408e-07, 2.1250e-07, 1.5206e-06,  ..., 8.4228e-08, 1.2688e-07,\n",
            "         9.9989e-01]], grad_fn=<SelectBackward>)\n",
            "tensor([[8.2360e-02, 3.5978e-02, 3.7318e-03,  ..., 5.0180e-05, 5.8638e-05,\n",
            "         6.9420e-04],\n",
            "        [2.3550e-01, 2.4390e-01, 1.4709e-01,  ..., 2.9023e-05, 3.1910e-05,\n",
            "         1.5084e-04],\n",
            "        [3.7573e-03, 1.5324e-03, 3.6006e-03,  ..., 5.2629e-05, 5.0621e-05,\n",
            "         7.8581e-04],\n",
            "        ...,\n",
            "        [1.8317e-07, 1.3069e-07, 6.3326e-07,  ..., 2.8078e-08, 3.9596e-08,\n",
            "         9.9996e-01],\n",
            "        [1.8050e-07, 1.3226e-07, 6.3907e-07,  ..., 2.8855e-08, 4.0923e-08,\n",
            "         9.9996e-01],\n",
            "        [1.7828e-07, 1.3294e-07, 6.4355e-07,  ..., 2.9286e-08, 4.1743e-08,\n",
            "         9.9996e-01]], grad_fn=<SelectBackward>)\n",
            "tensor([[8.2360e-02, 3.5978e-02, 3.7318e-03,  ..., 5.0180e-05, 5.8638e-05,\n",
            "         6.9420e-04],\n",
            "        [2.2199e-01, 3.5644e-02, 5.1312e-02,  ..., 4.9920e-05, 4.8833e-05,\n",
            "         1.8221e-04],\n",
            "        [1.2899e-02, 7.2415e-03, 6.1174e-02,  ..., 1.0374e-04, 7.5210e-05,\n",
            "         7.4501e-04],\n",
            "        ...,\n",
            "        [1.5478e-07, 1.4952e-07, 6.0046e-07,  ..., 3.2230e-08, 4.7567e-08,\n",
            "         9.9997e-01],\n",
            "        [1.5542e-07, 1.4945e-07, 6.0142e-07,  ..., 3.2038e-08, 4.7393e-08,\n",
            "         9.9997e-01],\n",
            "        [1.5614e-07, 1.4949e-07, 6.0318e-07,  ..., 3.1833e-08, 4.7170e-08,\n",
            "         9.9997e-01]], grad_fn=<SelectBackward>)\n",
            "tensor([[8.2360e-02, 3.5978e-02, 3.7318e-03,  ..., 5.0180e-05, 5.8638e-05,\n",
            "         6.9420e-04],\n",
            "        [3.3387e-01, 1.3861e-01, 8.6948e-02,  ..., 2.4439e-05, 1.3735e-05,\n",
            "         1.5135e-05],\n",
            "        [2.6748e-02, 2.7373e-02, 3.2505e-03,  ..., 1.9358e-04, 1.7669e-04,\n",
            "         6.3309e-04],\n",
            "        ...,\n",
            "        [4.2739e-01, 6.7599e-02, 8.9782e-03,  ..., 7.7715e-06, 4.9825e-06,\n",
            "         8.6915e-04],\n",
            "        [1.7591e-03, 2.8679e-04, 1.6743e-01,  ..., 1.1766e-05, 1.0989e-05,\n",
            "         5.6617e-03],\n",
            "        [5.3938e-04, 8.8712e-05, 2.7099e-04,  ..., 3.3429e-06, 4.8886e-06,\n",
            "         9.5996e-01]], grad_fn=<SelectBackward>)\n",
            "tensor([[8.2360e-02, 3.5978e-02, 3.7318e-03,  ..., 5.0180e-05, 5.8638e-05,\n",
            "         6.9420e-04],\n",
            "        [9.5685e-02, 6.0006e-01, 1.6677e-01,  ..., 1.8512e-05, 1.5735e-05,\n",
            "         5.3104e-06],\n",
            "        [3.1272e-04, 1.7759e-04, 4.7097e-04,  ..., 1.3270e-05, 1.8033e-05,\n",
            "         9.5406e-05],\n",
            "        ...,\n",
            "        [1.5319e-07, 1.4103e-07, 6.8179e-07,  ..., 2.4572e-08, 3.5710e-08,\n",
            "         9.9997e-01],\n",
            "        [1.5366e-07, 1.4156e-07, 6.6754e-07,  ..., 2.5473e-08, 3.7226e-08,\n",
            "         9.9997e-01],\n",
            "        [1.5429e-07, 1.4215e-07, 6.5812e-07,  ..., 2.6133e-08, 3.8330e-08,\n",
            "         9.9997e-01]], grad_fn=<SelectBackward>)\n",
            "tensor([[8.2360e-02, 3.5978e-02, 3.7318e-03,  ..., 5.0180e-05, 5.8638e-05,\n",
            "         6.9420e-04],\n",
            "        [2.3550e-01, 2.4390e-01, 1.4709e-01,  ..., 2.9023e-05, 3.1910e-05,\n",
            "         1.5084e-04],\n",
            "        [9.0709e-04, 2.0869e-03, 6.1465e-03,  ..., 6.0643e-05, 7.6120e-05,\n",
            "         7.8015e-04],\n",
            "        ...,\n",
            "        [1.7035e-07, 1.3271e-07, 6.3083e-07,  ..., 3.0089e-08, 4.3343e-08,\n",
            "         9.9997e-01],\n",
            "        [1.7038e-07, 1.3343e-07, 6.3380e-07,  ..., 2.9974e-08, 4.3300e-08,\n",
            "         9.9997e-01],\n",
            "        [1.7049e-07, 1.3413e-07, 6.3645e-07,  ..., 2.9855e-08, 4.3244e-08,\n",
            "         9.9997e-01]], grad_fn=<SelectBackward>)\n",
            "tensor([[8.2360e-02, 3.5978e-02, 3.7318e-03,  ..., 5.0180e-05, 5.8638e-05,\n",
            "         6.9420e-04],\n",
            "        [3.9928e-01, 1.6023e-01, 1.3239e-02,  ..., 2.6358e-05, 2.0845e-05,\n",
            "         3.9992e-05],\n",
            "        [3.7318e-03, 3.2098e-03, 1.0344e-02,  ..., 6.2333e-05, 5.2060e-05,\n",
            "         4.8271e-04],\n",
            "        ...,\n",
            "        [1.6063e-07, 1.5301e-07, 6.3778e-07,  ..., 3.2143e-08, 4.7423e-08,\n",
            "         9.9997e-01],\n",
            "        [1.6011e-07, 1.5077e-07, 6.3368e-07,  ..., 3.1712e-08, 4.6949e-08,\n",
            "         9.9997e-01],\n",
            "        [1.6026e-07, 1.4962e-07, 6.3274e-07,  ..., 3.1343e-08, 4.6513e-08,\n",
            "         9.9997e-01]], grad_fn=<SelectBackward>)\n",
            "tensor([[8.2360e-02, 3.5978e-02, 3.7318e-03,  ..., 5.0180e-05, 5.8638e-05,\n",
            "         6.9420e-04],\n",
            "        [3.9928e-01, 1.6023e-01, 1.3239e-02,  ..., 2.6358e-05, 2.0845e-05,\n",
            "         3.9992e-05],\n",
            "        [6.7933e-03, 3.3332e-03, 6.3248e-03,  ..., 3.4831e-05, 2.5385e-05,\n",
            "         5.7722e-05],\n",
            "        ...,\n",
            "        [1.4436e-07, 1.5946e-07, 6.8339e-07,  ..., 2.7872e-08, 4.0062e-08,\n",
            "         9.9997e-01],\n",
            "        [1.4145e-07, 1.4936e-07, 6.3321e-07,  ..., 2.8888e-08, 4.1653e-08,\n",
            "         9.9997e-01],\n",
            "        [1.4158e-07, 1.4674e-07, 6.1576e-07,  ..., 2.9288e-08, 4.2391e-08,\n",
            "         9.9997e-01]], grad_fn=<SelectBackward>)\n",
            "tensor([[8.2360e-02, 3.5978e-02, 3.7318e-03,  ..., 5.0180e-05, 5.8638e-05,\n",
            "         6.9420e-04],\n",
            "        [1.4577e-03, 3.7237e-04, 6.6274e-04,  ..., 2.2541e-05, 2.4031e-05,\n",
            "         2.7844e-05],\n",
            "        [8.2629e-02, 1.6929e-02, 6.2168e-02,  ..., 9.6259e-05, 1.1062e-04,\n",
            "         5.3963e-04],\n",
            "        ...,\n",
            "        [1.5058e-07, 1.4421e-07, 6.6186e-07,  ..., 2.9133e-08, 4.3593e-08,\n",
            "         9.9997e-01],\n",
            "        [1.5129e-07, 1.4490e-07, 6.5707e-07,  ..., 2.9242e-08, 4.3760e-08,\n",
            "         9.9997e-01],\n",
            "        [1.5195e-07, 1.4533e-07, 6.5321e-07,  ..., 2.9323e-08, 4.3880e-08,\n",
            "         9.9997e-01]], grad_fn=<SelectBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxF1cRC2b3bk",
        "colab_type": "text"
      },
      "source": [
        "**2.8 (5 points)** Write a function that generates a single word (sequence of indexes) given the model. Do not forget about the hidden state! Be careful about start and end symbol indexes. Use ``torch.multinomial`` for sampling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiicRLnNb3bl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate(model, max_length=20, start_index=BEGIN_INDEX, end_index=END_INDEX):\n",
        "    \"\"\"\n",
        "    == YOUR CODE HERE ==\n",
        "    \"\"\"\n",
        "\n",
        "    for i in range(max_length):\n",
        "      input = torch.full((1, 1), start_index, dtype=torch.long)\n",
        "      output = model(input)\n",
        "      #print(output[0][0].shape)\n",
        "      probab = torch.softmax(output, -1).reshape(-1)\n",
        "      #print(probab.shape)\n",
        "      generated = torch.multinomial(probab, 1).item()\n",
        "      #print(generated)\n",
        "      if generated == end_index:\n",
        "        break\n",
        "\n",
        "      if generated == start_index:\n",
        "        generated = ''\n",
        "\n",
        "      yield generated\n",
        "\n",
        "def index_to_char(index):\n",
        "    index_to_char = vocab._i2t.copy()\n",
        "    # print(index)\n",
        "    return index_to_char[index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7TeAZA9b3bo",
        "colab_type": "text"
      },
      "source": [
        "**2.9 (1 points)** Use ``generate`` to sample 20 pseudowords. Do not forget to transform indexes to letters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqkpuA09b3bp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "46a480a3-e2f3-4527-c1f9-154f90acfb25"
      },
      "source": [
        "for i in range(20):\n",
        "    print(''.join([index_to_char(index) for index in generate(model)]))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "нмозксвнирппсцосуанн\n",
            "зрбубсдуообсокучжзоо\n",
            "пгцписоприппугнарбор\n",
            "иобзпуосбзоцзмнагрсо\n",
            "пВслкоилпроивфабрумп\n",
            "бпндвпадопуоппнниаик\n",
            "ущшвпабкпипрчзтпгкбб\n",
            "пуппбврргоппцоуптппп\n",
            "жммзорбскркотопвзоез\n",
            "пбпппбруспапррзвпочп\n",
            "мббпвпрпурмопбпснамс\n",
            "тупорпдбпнсспмпипаки\n",
            "гкпаорвзбббпдовпнрип\n",
            "убсочвмнвпсдркртубдк\n",
            "ряаонсбкнкаумзп\n",
            "аспддоббуизорнвосвпс\n",
            "снпсомцмолзрпакубппв\n",
            "нпаорпуупикквтаансзв\n",
            "вкаивсбввсзпрзцрроуя\n",
            "исдикмпнбркогвмудспв\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uhFpkzob3br",
        "colab_type": "text"
      },
      "source": [
        "**(2.10) 5 points** Write a batched version of the generation function. You should sample the following symbol only for the words that are not finished yet, so apply a boolean mask to trace active words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPWgFPmAb3bs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from copy import copy\n",
        "from itertools import filterfalse\n",
        "\n",
        "def generate_batch(model, batch_size, max_length = 20, start_index=1, end_index=2):\n",
        "    symbols = torch.full((batch_size, 1), start_index).type(torch.LongTensor)\n",
        "    indexs = [copy(symbols)]\n",
        "\n",
        "    active_words = np.ones(batch_size, dtype=np.bool)\n",
        "\n",
        "    for i in range(max_length):\n",
        "        prediction = model(symbols[active_words])\n",
        "        probability = torch.softmax(prediction, -1)\n",
        "        probability = probability.reshape(-1, probability.shape[-1])\n",
        "\n",
        "        symbols[active_words] = torch.multinomial(probability, 1)\n",
        "        indexs.append(copy(symbols))\n",
        "        active_words = symbols.numpy().reshape(-1) != end_index\n",
        "\n",
        "    return torch.stack(indexs, axis=1).squeeze_(-1)\n",
        "    \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsfFxfr6b3bu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "outputId": "88757335-72f0-4c55-a0ea-786cbd702d22"
      },
      "source": [
        "generated = []\n",
        "for _ in range(2):\n",
        "    generated += generate_batch(model, batch_size=10)\n",
        "\n",
        "print(generated)\n",
        "generated = [[index_to_char(index) for index in tensor] for tensor in generated]\n",
        "print(generated)\n",
        "\"\"\"\n",
        "== YOUR CODE HERE ==\n",
        "\"\"\"\n",
        "for elem in generated:\n",
        "    print(\"\".join(elem))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), tensor([17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
            "        17, 17, 17]), tensor([53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53,\n",
            "        53, 53, 53]), tensor([21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
            "        21, 21, 21]), tensor([53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53,\n",
            "        53, 53, 53]), tensor([53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53,\n",
            "        53, 53, 53]), tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), tensor([21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
            "        21, 21, 21]), tensor([53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53,\n",
            "        53, 53, 53]), tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
            "        10, 10, 10]), tensor([53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53,\n",
            "        53, 53, 53]), tensor([53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53,\n",
            "        53, 53, 53]), tensor([53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53,\n",
            "        53, 53, 53]), tensor([48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48,\n",
            "        48, 48, 48]), tensor([30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
            "        30, 30, 30]), tensor([12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
            "        12, 12, 12]), tensor([53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53,\n",
            "        53, 53, 53]), tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), tensor([18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
            "        18, 18, 18]), tensor([53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53,\n",
            "        53, 53, 53])]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-c57623bb127d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mgenerated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_to_char\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerated\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \"\"\"\n",
            "\u001b[0;32m<ipython-input-36-c57623bb127d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mgenerated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_to_char\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerated\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \"\"\"\n",
            "\u001b[0;32m<ipython-input-36-c57623bb127d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mgenerated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_to_char\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerated\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \"\"\"\n",
            "\u001b[0;32m<ipython-input-34-8fcf0cbd5afd>\u001b[0m in \u001b[0;36mindex_to_char\u001b[0;34m(index)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mindex_to_char\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_i2t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# print(index)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mindex_to_char\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AL8As6Jhb3bw",
        "colab_type": "text"
      },
      "source": [
        "**(2.11) 5 points** Experiment with the type of RNN, number of layers, units and/or dropout to improve the perplexity of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kN62B12b3bx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}